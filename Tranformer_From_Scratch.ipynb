{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhant-uniyal/NLP/blob/main/Tranformer_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRcJrkcKuvt9"
      },
      "source": [
        "### Importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFAtZmUtuz2S",
        "outputId": "5b6c4064-17ae-47ad-e274-4b5180b6a42f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.layers import Attention, Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "from tensorflow.python.keras import backend as K\n",
        "import gc\n",
        "en_stopwords = stopwords.words('english')\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j2mpmwEu7sT",
        "outputId": "cf8d03a7-c903-4cdd-816f-e63ce0e3fd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMvxfeZzwLm4"
      },
      "source": [
        "### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJPJnx-vwOjv"
      },
      "outputs": [],
      "source": [
        "max_len_text=80\n",
        "max_len_summary=10\n",
        "epochs=10\n",
        "number_of_datapoints=100000\n",
        "\n",
        "logger = tf.get_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2WUb56Yzlbr"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"/content/gdrive/MyDrive/Reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SvCZ_s29z8Dr",
        "outputId": "0e9a2b51-c9ad-420a-faa9-611a961ccd8f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-83c544de-cf60-49e3-b752-b5f8e2c45cf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>568450</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Lettie D. Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1299628800</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>Great for sesame chicken..this is a good if not better than resturants I have eaten at..My husband loved it..will find other recipes to use this in..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>568451</td>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>A3I8AFVPEE8KI5</td>\n",
              "      <td>R. Sawyer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1331251200</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>I'm disappointed with the flavor. The chocolate notes are especially weak. Milk thickens it but the flavor still disappoints. This was worth a try but I'll never buy again. I will use what's left,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>568452</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>pksd \"pk_007\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1329782400</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>These stars are small, so you can give 10-15 of those in one training session.  I tried to train our dog with \"Ceaser dog treats\",  it just made our puppy hyper.  If you compare the ingredients, y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>568453</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>Kathy A. Welch \"katwel\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1331596800</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>These are the BEST treats for training and rewarding your dog for being good while grooming.  Lower in calories and loved by all the doggies.  Sweet potatoes seem to be their favorite Wet Noses tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>568454</td>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>srfell17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1338422400</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83c544de-cf60-49e3-b752-b5f8e2c45cf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83c544de-cf60-49e3-b752-b5f8e2c45cf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83c544de-cf60-49e3-b752-b5f8e2c45cf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82732425-7a6c-4310-a0b3-5c3d0148eb0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82732425-7a6c-4310-a0b3-5c3d0148eb0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82732425-7a6c-4310-a0b3-5c3d0148eb0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ff2e5bf1-04c1-42e8-9080-efa1d8ff6ad9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ff2e5bf1-04c1-42e8-9080-efa1d8ff6ad9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            Id   ProductId          UserId                      ProfileName  \\\n",
              "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "...        ...         ...             ...                              ...   \n",
              "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
              "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
              "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
              "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
              "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
              "\n",
              "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                          1                       1      5  1303862400   \n",
              "1                          0                       0      1  1346976000   \n",
              "2                          1                       1      4  1219017600   \n",
              "3                          3                       3      2  1307923200   \n",
              "4                          0                       0      5  1350777600   \n",
              "...                      ...                     ...    ...         ...   \n",
              "568449                     0                       0      5  1299628800   \n",
              "568450                     0                       0      2  1331251200   \n",
              "568451                     2                       2      5  1329782400   \n",
              "568452                     1                       1      5  1331596800   \n",
              "568453                     0                       0      5  1338422400   \n",
              "\n",
              "                                   Summary  \\\n",
              "0                    Good Quality Dog Food   \n",
              "1                        Not as Advertised   \n",
              "2                    \"Delight\" says it all   \n",
              "3                           Cough Medicine   \n",
              "4                              Great taffy   \n",
              "...                                    ...   \n",
              "568449                 Will not do without   \n",
              "568450                        disappointed   \n",
              "568451            Perfect for our maltipoo   \n",
              "568452  Favorite Training and reward treat   \n",
              "568453                         Great Honey   \n",
              "\n",
              "                                                                                                                                                                                                           Text  \n",
              "0       I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  \n",
              "1                Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
              "2       This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...  \n",
              "3       If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  \n",
              "4                                                                  Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  \n",
              "...                                                                                                                                                                                                         ...  \n",
              "568449                                                    Great for sesame chicken..this is a good if not better than resturants I have eaten at..My husband loved it..will find other recipes to use this in..  \n",
              "568450  I'm disappointed with the flavor. The chocolate notes are especially weak. Milk thickens it but the flavor still disappoints. This was worth a try but I'll never buy again. I will use what's left,...  \n",
              "568451  These stars are small, so you can give 10-15 of those in one training session.  I tried to train our dog with \"Ceaser dog treats\",  it just made our puppy hyper.  If you compare the ingredients, y...  \n",
              "568452  These are the BEST treats for training and rewarding your dog for being good while grooming.  Lower in calories and loved by all the doggies.  Sweet potatoes seem to be their favorite Wet Noses tr...  \n",
              "568453                                                                                          I am very satisfied ,product is as advertised, I use it on cereal, with raw vinegar, and as a general sweetner.  \n",
              "\n",
              "[568454 rows x 10 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxXCVXL80fqy"
      },
      "outputs": [],
      "source": [
        "data = data[:number_of_datapoints].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnSkrfPRkIYh"
      },
      "outputs": [],
      "source": [
        "# from stack overflow\n",
        "contraction_mapping = {\n",
        "    \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
        "    \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
        "    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
        "}\n",
        "contractions = list(contraction_mapping.keys())\n",
        "sources = list(contraction_mapping.values())\n",
        "max_source_len , min_source_len = max(len(source.split()) for source in sources) , min(len(source.split()) for source in sources)\n",
        "windows = np.arange(max_source_len , min_source_len -1 , -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua-XFyMPv2Td"
      },
      "source": [
        "### Utility Data Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCf_UgnQ2mfL"
      },
      "outputs": [],
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)' , ' ' , newString)#first remove all text within parentheses including parentheses themselves\n",
        "    newString = re.sub(r'\"' , ' ' , newString) #second remove all \" and replace with space\n",
        "    words = newString.split() # check if contractions can be made , if yes , make them\n",
        "    for window in windows:\n",
        "      for i in range(len(words)-window+1):\n",
        "        curr_sources = ' '.join(words[i:i+window])\n",
        "        try:\n",
        "          position = sources.index(curr_sources)\n",
        "        except:\n",
        "          position = None\n",
        "        if position:\n",
        "          words[i] = contractions[position]\n",
        "          del words[i+1:i+window]\n",
        "    newString = ' '.join(words)\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(r\"[^a-zA-Z]\", \" \", newString)\n",
        "    tokens = [word for word in newString.split() if word not in en_stopwords]\n",
        "    long_words=[]\n",
        "    for token in tokens:\n",
        "        if len(token) >= 3:\n",
        "          long_words.append(token)\n",
        "    return (\" \".join(long_words)).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgfY-CQwv_xh"
      },
      "outputs": [],
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\"' , ' ' , newString) #first remove all \" and replace with space\n",
        "    words = newString.split() # check if contractions can be made , if yes , make them\n",
        "    windows = np.arange(min_source_len , max_source_len + 1)\n",
        "    for window in windows:\n",
        "      for i in range(len(words)-window+1):\n",
        "        curr_sources = ' '.join(words[i:i+window])\n",
        "        try:\n",
        "          position = sources.index(curr_sources)\n",
        "        except:\n",
        "          position = None\n",
        "        if position:\n",
        "          words[i] = contractions[position]\n",
        "          del words[i+1:i+window]\n",
        "    newString = ' '.join(words)\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:\n",
        "            newString=newString+i+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir8cZ_QqvWV3"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_sCNhXsvkyT",
        "outputId": "39921ce1-bf71-4b71-eb62-c6ef5ae960d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   index                   100000 non-null  int64 \n",
            " 1   Id                      100000 non-null  int64 \n",
            " 2   ProductId               100000 non-null  object\n",
            " 3   UserId                  100000 non-null  object\n",
            " 4   ProfileName             99994 non-null   object\n",
            " 5   HelpfulnessNumerator    100000 non-null  int64 \n",
            " 6   HelpfulnessDenominator  100000 non-null  int64 \n",
            " 7   Score                   100000 non-null  int64 \n",
            " 8   Time                    100000 non-null  int64 \n",
            " 9   Summary                 99998 non-null   object\n",
            " 10  Text                    100000 non-null  object\n",
            "dtypes: int64(6), object(5)\n",
            "memory usage: 8.4+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 99992 entries, 0 to 99999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   index                   99992 non-null  int64 \n",
            " 1   Id                      99992 non-null  int64 \n",
            " 2   ProductId               99992 non-null  object\n",
            " 3   UserId                  99992 non-null  object\n",
            " 4   ProfileName             99992 non-null  object\n",
            " 5   HelpfulnessNumerator    99992 non-null  int64 \n",
            " 6   HelpfulnessDenominator  99992 non-null  int64 \n",
            " 7   Score                   99992 non-null  int64 \n",
            " 8   Time                    99992 non-null  int64 \n",
            " 9   Summary                 99992 non-null  object\n",
            " 10  Text                    99992 non-null  object\n",
            "dtypes: int64(6), object(5)\n",
            "memory usage: 9.2+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()\n",
        "data.drop_duplicates(inplace = True)\n",
        "data.dropna(inplace = True)\n",
        "data.info()\n",
        "number_of_datapoints = data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I7C1CqE9H6w"
      },
      "outputs": [],
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8dOBJu09LOk"
      },
      "outputs": [],
      "source": [
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "\n",
        "data = data[data[\"cleaned_summary\"] != \"\"]\n",
        "number_of_datapoints = data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR5qt5xVwCmi"
      },
      "outputs": [],
      "source": [
        "data['cleaned_summary'] = list(map(lambda x : f\"_START_ {x} _END_\" , data['cleaned_summary']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIV8VJYDwDxY",
        "outputId": "6d8573de-b3b9-4157-e249-d2fdaadc8f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Summary: _START_ good quality dog food  _END_\n",
            "\n",
            "\n",
            "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Summary: _START_ not as advertised  _END_\n",
            "\n",
            "\n",
            "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Summary: _START_ delight says it all  _END_\n",
            "\n",
            "\n",
            "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
            "Summary: _START_ cough medicine  _END_\n",
            "\n",
            "\n",
            "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Summary: _START_ great taffy  _END_\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(\"Review:\",data['cleaned_text'][i])\n",
        "    print(\"Summary:\",data['cleaned_summary'][i])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVWnGreP9pVj"
      },
      "source": [
        "### Analysis of Sentence and Summary Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "sun9go_s9kwN",
        "outputId": "e68623ea-c09f-4ae1-bd82-3fdb0c00eb0d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "for text in data['Text']:\n",
        "  text_word_count.append(len(text.split()))\n",
        "\n",
        "for summary in data['Summary']:\n",
        "  summary_word_count.append(len(summary.split()) - 2)\n",
        "\n",
        "max_len_summary = max(summary_word_count) + 2\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
        "\n",
        "axes[0].hist(text_word_count, bins=5, color='Yellow', edgecolor='black')\n",
        "axes[0].set_title('Text Word Count')\n",
        "\n",
        "axes[1].hist(summary_word_count, bins=5, color='Pink', edgecolor='black')\n",
        "axes[1].set_title('Summary Word Count')\n",
        "\n",
        "for ax in axes:\n",
        "    ax.set_xlabel('Lengths')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNNRJfB69vM6"
      },
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cyXOOrw-S5a"
      },
      "outputs": [],
      "source": [
        "tokenizer_x = Tokenizer()\n",
        "tokenizer_x.fit_on_texts(data['cleaned_text'])\n",
        "\n",
        "tokenizer_y = Tokenizer()\n",
        "tokenizer_y.fit_on_texts(data['cleaned_summary'])\n",
        "\n",
        "data['cleaned_text_encoded'] = tokenizer_x.texts_to_sequences(data['cleaned_text'])\n",
        "data['cleaned_summary_encoded'] = tokenizer_y.texts_to_sequences(data['cleaned_summary'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RllfIozDBtBn"
      },
      "outputs": [],
      "source": [
        "data = data[data['cleaned_text_encoded'].apply(lambda x: len(x) <= max_len_text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiHYnrnc9sU5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(data['cleaned_text_encoded'],data['cleaned_summary_encoded'],test_size=0.1,random_state=0,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGRNZtkb9xhx"
      },
      "outputs": [],
      "source": [
        "x_tr = np.array(pad_sequences(x_tr , padding = \"pre\" , maxlen = max_len_text))\n",
        "x_val = np.array(pad_sequences(x_val , padding = \"pre\" , maxlen = max_len_text))\n",
        "\n",
        "x_voc_size = len(tokenizer_x.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4cZgAaQst7-",
        "outputId": "6d5be0e0-7ac4-4d10-a871-1bbb2f566a04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0, 1211,  514, 5477,   57,\n",
              "          4,    3,  800], dtype=int32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_tr[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "led-SAKh9yY4",
        "outputId": "4d5f6b69-fd47-44a4-c242-753aab3a9deb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "91027"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_tr = np.array(pad_sequences(y_tr , padding = \"pre\" , maxlen = max_len_summary))\n",
        "y_val = np.array(pad_sequences(y_val , padding = \"pre\" , maxlen = max_len_summary))\n",
        "\n",
        "y_voc_size = len(tokenizer_y.word_index) + 1\n",
        "\n",
        "number_of_datapoints = data.shape[0]\n",
        "\n",
        "number_of_datapoints #number of timestamps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFEH5fjU-p_L"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1zlVmdA-r0_",
        "outputId": "9efe48a8-fc6f-41d1-8b5e-f16d99cbafd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 80)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 80, 500)              2715450   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 80, 512)              2074624   ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 80, 512)              2099200   ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 500)            2715450   ['input_2[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 80, 512),            2099200   ['lstm_1[0][0]']              \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 512),          2074624   ['embedding_1[0][0]',         \n",
            "                              (None, 512),                           'lstm_2[0][1]',              \n",
            "                              (None, 512)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, None, 512),          524800    ['lstm_2[0][0]',              \n",
            " Layer)                       (None, None, 80))                      'lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)  (None, None, 1024)           0         ['lstm_3[0][0]',              \n",
            "                                                                     'attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 14866)          1523765   ['concat_layer[0][0]']        \n",
            " ributed)                                                 0                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 78419098 (299.15 MB)\n",
            "Trainable params: 78419098 (299.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "embed_dim = 500 #every word goes from 80d vector to 500d vector\n",
        "encoder_lstm_units = 512\n",
        "decoder_lstm_units = 512 # we are using 512 units in all 3 LSTM layers of encoder and single LSTM layer of decoder\n",
        "\n",
        "#first step : taking input of sequences , each of shape : (80,)\n",
        "encoder_inputs = Input(shape=(max_len_text,))\n",
        "\n",
        "#second step : getting embeddings of each word from the lookup table\n",
        "enc_emb = Embedding(x_voc_size, embed_dim, trainable=True)(encoder_inputs)\n",
        "\n",
        "#third step : encoding\n",
        "\n",
        "#encoder architecture:\n",
        "#3 lstm layers stacked on each other. output of one is the input of other , so each output is better than the last\n",
        "#note : return_sequences = True , gives hidden state output of each timestep. hence this is needed for encoder\n",
        "# return_state = True , gives only hidden state output and cell state output at last timestep. so this is also needed to initialize decoder , although only in the last layer of the LSTM stack.\n",
        "\n",
        "#shapes:\n",
        "#number of timesteps = number of datapoints = number of words in the sentence provided = 80 (max_len_text)\n",
        "#number of features = dimensionality of each word = 512 (embedding dim , which we specified above)\n",
        "#number of samples = 1 (one sentence at a time)\n",
        "#hence input of each lstm layer is (n_samples , n_timesteps , n_features) = (1 , 80 , 512)\n",
        "#now output shape differs , n_features becomes n_lstm_units , but here both are equal.\n",
        "#so input and output shapes are equal , hence it's ok to propogate outputs throughout the stack\n",
        "\n",
        "encoder_lstm1 = LSTM(encoder_lstm_units , return_sequences = True)\n",
        "encoder_output1= encoder_lstm1(enc_emb) #no need to store last h and c\n",
        "\n",
        "encoder_lstm2 = LSTM(encoder_lstm_units , return_sequences = True)\n",
        "encoder_output2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "encoder_lstm3 = LSTM(encoder_lstm_units , return_sequences = True , return_state = True)\n",
        "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2) #no we need last h and c , for the decoder\n",
        "\n",
        "#4th step : decoding\n",
        "\n",
        "decoder_inputs = Input(shape=(None,)) #None means it can take a sequence of any length , which is needed in the decoder for variable length outputs\n",
        "dec_emb = Embedding(x_voc_size, embed_dim, trainable=True)(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(decoder_lstm_units , return_sequences = True , return_state = True)\n",
        "decoder_output, _ , _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])\n",
        "\n",
        "#4th step : attention , decoding and attention are basically parallel , so thats why both basically happen in the same step\n",
        "\n",
        "'''\n",
        "how attention works:\n",
        "each datapoint now has it's corresponding hidden state stored -> so [h1 , h2 , ... h_n]\n",
        "from all these we get a context vector s0 , which is the initial state of the decoder\n",
        "we check how well s0 matches with each recorded hidden state , using an align function.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "      super(AttentionLayer,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "\n",
        "        #when we call build for this layer , we are passing encoder and decoder's output shapes\n",
        "        enc_units = input_shape[0][2] #so they are both just n_lstm_units which is 512 for both encoder and decoder\n",
        "        dec_units = input_shape[1][2]\n",
        "\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((dec_units, enc_units)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((enc_units, enc_units)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((enc_units, 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
        "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            logger.debug(\"Running energy computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_full_seq , self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "\n",
        "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "\n",
        "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            logger.debug(\"Running attention vector computation step\")\n",
        "\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
        "\n",
        "            encoder_full_seq = states[-1]#Extract the final state from the states list\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "\n",
        "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
        "\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        # we don't maintain states between steps when computing attention\n",
        "        # attention is stateless, so we're passing a fake state for RNN step function\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n",
        "\n",
        "\n",
        "attn_layer = AttentionLayer(name = 'attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_output3, decoder_output])\n",
        "\n",
        "# concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_output, attn_out])\n",
        "\n",
        "\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0pnDoNhGUoQ"
      },
      "source": [
        "encoder decoder notes :\n",
        "\n",
        "The problem with a simple encoder decoder model is that we hardcode one single representation of the input. Now , during decoding , we have to check whether the output aligns with this single representation. The problem arises when the sentence is so long , that one representation isn't enough , because the model fails to capture long term dependencies.\n",
        "\n",
        "Maybe we can connect each word of the input to every word of the output , by creating one big vector by concatenating all the vectors of the input.This fixes the problem of forgetting, since the output vector now has the information of every single input word. But then , this assumes that each word of the output depends on every single word of the input regardless , which doesn't make sense. Also , the problem of hardcoding one single representation still exists.\n",
        "\n",
        "The main problem we keep facing is of dynamic dependence. seq2seq problems requires proper focus on appropriate parts of the input. We can't decide ourselves that the entire input is important. We also can't hardcode a single representation of the input, to decode each output word.\n",
        "\n",
        "Attention fixes this problem by doing dynamic weighting. We are still going to connect every word of the input to each word of the output, but now , each connection will have a weight(attention score) , signifying it's importance.\n",
        "\n",
        "We basically generate a database , where primary key = input word and the value for each primary key = it's hidden state representation. Now , at each time step of decoding , we ask the question(query) -> how important is each input word to the output right now? We answer this question by retrieving the value of each key and weighing it against the attention vector , which is generated for each output word.The vector contains the attention scores of each input word..These scores are parameters , and since they are parameters , they can be tuned using a neural network.\n",
        "\n",
        "Hence the shape of the database will the output_len X input_len , where the rows are the attention vectors for each output_word , and each column of the row contains the attention score of that input word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIkGlDTP-taR"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqNO-BEO-va8",
        "outputId": "2c618a9e-5b45-4b7e-a3cb-fd93ca81f7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/161 [..............................] - ETA: 6:06:56 - loss: 9.5448"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-df3d8de8423e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=epochs,batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y_OOUZ9UHruQ"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjrJJIbD-08C"
      },
      "source": [
        "### Post Training Analysis & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHkw1xXd-zAl"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R2QkS5FW-4Za"
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index = tokenizer_y.index_word\n",
        "reverse_source_word_index = tokenizer_x.index_word\n",
        "target_word_index = tokenizer_y.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EnkAqbir-7D-"
      },
      "outputs": [],
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(encoder_inputs, [encoder_output3, state_h3, state_c3])\n",
        "\n",
        "# decoder inference\n",
        "decoder_state_input_h = Input(shape=(decoder_lstm_units,))\n",
        "decoder_state_input_c = Input(shape=(decoder_lstm_units,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,decoder_lstm_units))\n",
        "\n",
        "decoder_inputs2 = Input(shape = (None,))\n",
        "dec_emb2= Embedding(x_voc_size, embed_dim, trainable=True)(decoder_inputs2)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_layer2 = AttentionLayer(name = 'attention_layer_inf')\n",
        "attn_out_inf, attn_states_inf = attn_layer2([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "decoder_dense2 = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs2 = decoder_dense2(decoder_inf_concat)\n",
        "\n",
        "\n",
        "decoder_model = Model(\n",
        "[decoder_inputs2] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JAE4BABq0qKc"
      },
      "outputs": [],
      "source": [
        "sos_token_index = target_word_index[\"start\"]\n",
        "eos_token = \"end\"\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, y_voc_size))\n",
        "\n",
        "    target_seq[0,0,sos_token_index] = 1\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "\n",
        "        dec_out, dec_h, dec_c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        sampled_token_index = np.argmax(dec_out[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index + 1]\n",
        "\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        if sampled_token == eos_token or len(decoded_sentence.split()) > max_len_summary:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1,y_voc_size))\n",
        "        target_seq[0, 0,sampled_token_index] = 1\n",
        "\n",
        "        e_out , e_h, e_c = dec_out ,dec_h, dec_c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NtJ-SW5J-9lG"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "\n",
        "  new_string = ''\n",
        "  for i in input_seq:\n",
        "      if i != 0:\n",
        "          new_string += reverse_source_word_index[i] + ' '\n",
        "  return new_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PZHaQnh9--m5"
      },
      "outputs": [],
      "source": [
        "i=1\n",
        "print(\"Review:\",seq2text(x_val[i]))\n",
        "print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text))[:18])\n",
        "print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}